ğŸ¨ Fine-Tuning de ResNet18 sur le Dataset MNIST

Ce projet prÃ©sente une implÃ©mentation complÃ¨te du fine-tuning du modÃ¨le ResNet18 sur le dataset MNIST, un classique de la classification dâ€™images manuscrites.
Lâ€™objectif est dâ€™adapter un modÃ¨le prÃ©-entraÃ®nÃ© sur ImageNet Ã  une tÃ¢che plus simple : la classification de chiffres (0â€“9).

ğŸš€ Objectifs du projet

Charger et prÃ©parer le dataset MNIST pour un rÃ©seau convolutif prÃ©-entraÃ®nÃ©.

Adapter ResNet18 pour une nouvelle tÃ¢che de classification.

EntraÃ®ner, optimiser et Ã©valuer les performances du modÃ¨le.

Visualiser les mÃ©triques d'entraÃ®nement : perte, prÃ©cision, etc.

ğŸ§  Architecture utilisÃ©e
ğŸ”¹ ResNet18 (prÃ©-entraÃ®nÃ© sur ImageNet)

RÃ©sidus d'identitÃ© et convolutionnels.

TrÃ¨s efficace mÃªme sur de petits datasets.

DerniÃ¨re couche modifiÃ©e pour 10 classes (sortie MNIST).

ğŸ”§ Technologies utilisÃ©es

Python

PyTorch

Torchvision

Matplotlib

Jupyter Notebook

ğŸ“‚ Structure du projet
ğŸ“ FineTuning-ResNet18-MNIST
â”‚
â”œâ”€â”€ FINE_TUNING_RESNET18_SUR_MNIST.ipynb
â””â”€â”€ README.md

ğŸ› ï¸ PrÃ©paration des donnÃ©es

Conversion MNIST en format 3 canaux (RGB) pour correspondre Ã  ImageNet.

Normalisation avec les statistiques standards ImageNet.

Split train / test.

Utilisation de DataLoader pour batching efficace.

ğŸ‹ï¸ EntraÃ®nement

Optimiseur : Adam ou SGD

Loss : CrossEntropyLoss

Scheduler (optionnel)

Fine-tuning total ou partiel selon les couches gelÃ©es

ğŸ“Š Ã‰valuation

Calcul de la prÃ©cision sur le dataset test

Visualisation :

courbe de perte (loss)

Ã©volution de la prÃ©cision

matrice de confusion (si incluse dans ton notebook)
